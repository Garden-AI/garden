{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Your Model ðŸŒ±GardenðŸŒ± Execution Environment\n",
        "\n",
        "Use this notebook to write a function that executes your model(s). Tag that function with the `@garden_pipeline` decorator.\n",
        "\n",
        "Garden will take this notebook and build a container with it. When Garden executes your `@garden_pipeline`, it will be like like you have just run all the cells of this notebook once. So you can install libraries with `!pip install` and your function can use those libraries. You can also define helper functions and constants to use in your `@garden_pipeline`."
      ],
      "metadata": {
        "id": "H24yDUiVP5-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from garden_ai.model_connectors import HFConnector\n",
        "from garden_ai import PipelineMetadata, garden_pipeline"
      ],
      "metadata": {
        "id": "qww1_jOzP5S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import joblib"
      ],
      "metadata": {
        "id": "b0s7Bealdp8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model connectors\n",
        "\n",
        "Model connectors let Garden import metadata about your model.\n",
        "They also have a `download` method that you can use to download your model weights."
      ],
      "metadata": {
        "id": "3aikfsCRdrEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_hugging_face_repo = HFConnector(\"garden-ai/sample_sklearn_model\")"
      ],
      "metadata": {
        "id": "H7em6SwMdvkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline metadata\n",
        "\n",
        "\n",
        "To publish your function, Garden needs metadata so that other users can discover it.\n",
        "Edit this PipelineMetadata object to describe your function.\n"
      ],
      "metadata": {
        "id": "FTziKOq7d1Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_pipeline_meta = PipelineMetadata(\n",
        "    title=\"My Inference Function\",\n",
        "    description=\"Write a longer description here so that people know what your it does.\",\n",
        "    authors=[\"you\", \"your collaborator\"],\n",
        "    tags=[\"materials science\", \"your actual field\"]\n",
        ")"
      ],
      "metadata": {
        "id": "PHtZD33NhCEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "\n",
        "Define any helper functions you need and use them in the function you want to let people run remotely"
      ],
      "metadata": {
        "id": "gnNDYs4PhKKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    input_df.fillna(0, inplace=True)\n",
        "    return input_df"
      ],
      "metadata": {
        "id": "hhd9FNB9hN0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write your pipeline function that will run remotely\n",
        "\n",
        "The `@garden_pipeline` decorator makes this function available to run in your garden when you publish the notebook.\n",
        "Download your model weights and call your model in this function.\n",
        "\n",
        "In the decorator be sure to include:\n",
        "- your pipeline metadata,\n",
        "- connectors for any models you're using,\n",
        "- the DOI of the garden you want this pipeline to be found in. (Check `garden-ai garden list` for the DOIs of your gardens.)"
      ],
      "metadata": {
        "id": "bDPkWjAShSKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@garden_pipeline(pipeline_meta=my_pipeline_meta,  model_connectors=[my_hugging_face_repo], garden_doi=\"10.23677/my-garden-doi\")\n",
        "def run_my_model(input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cleaned_df = preprocess(input_df)\n",
        "    download_path = my_hugging_face_repo.download()\n",
        "    model = joblib.load(f\"{download_path}/model.pkl\")\n",
        "    return model.predict(cleaned_df)"
      ],
      "metadata": {
        "id": "6ls-44Wehec9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test your pipeline function\n",
        "\n",
        "Finally, make sure your `@garden_pipeline` works!\n",
        "When Garden makes a container from your notebook, it runs all the cells in order and saves the notebook. Then users invoke your `@garden_pipeline` in the context of the notebook.\n",
        "\n",
        "If you can hit \"Kernel\" -> \"Restart and run all cells\" and your test below works, your `@garden_pipeline` will work in your garden!\n"
      ],
      "metadata": {
        "id": "dK3PHq2fhgxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with input that is relevant for your garden_pipeline\n",
        "example_input = pd.DataFrame({\n",
        "    'A': [1, 2, None, 4],\n",
        "    'B': [None, 2, 3, 4],\n",
        "    'C': [1, 2, 3, 4]\n",
        "})\n",
        "run_my_model(example_input)"
      ],
      "metadata": {
        "id": "pn2aa8wnhu2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9-UTFHAmCEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
